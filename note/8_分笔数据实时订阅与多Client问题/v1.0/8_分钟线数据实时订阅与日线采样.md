# 分钟线数据实时订阅与日线采样系统

## 项目概述

本系统旨在构建一个跨平台的分钟线数据实时订阅与处理平台，通过Windows电脑上的QMT接口实时获取股票分钟线数据，经过远程Redis消息队列缓冲，最终在苹果电脑上通过ClickHouse数据库进行存储和查询。同时提供Web可视化查询界面，支持多种时间周期的数据访问和图表展示。

### 核心功能
- **实时数据订阅**：Windows电脑通过QMT接口实时订阅分钟线数据
- **跨平台数据传输**：通过远程Redis消息队列实现Windows到Mac的数据传输
- **多周期数据支持**：支持1分钟、5分钟、30分钟、日线等多种时间周期
- **物化视图优化**：利用ClickHouse物化视图实现数据聚合和查询优化
- **Web可视化界面**：提供简洁易用的Web查询和图表展示界面
- **灵活查询SDK**：提供Python SDK支持程序化数据访问

## 系统架构设计

### 整体架构图
```
Windows电脑(QMT) → 远程Redis(8.217.201.221:16379) → Mac电脑(ClickHouse) → Web可视化界面
       ↓                    ↓                           ↓                ↓
   实时数据订阅          跨平台数据缓冲              持久化存储与查询      图表展示与交互
```

### 技术栈选择
- **数据源**：QMT (迅投QMT量化交易平台，Windows专用)
- **消息队列**：Redis (远程服务器 8.217.201.221:16379)
- **数据库**：ClickHouse (Mac电脑本地部署)
- **Web框架**：Flask/FastAPI + Vue.js
- **图表库**：ECharts/Chart.js
- **开发语言**：Python 3.8+
- **核心库**：xtquant, redis, clickhouse-driver, pandas, flask

## 数据存储与查询方案

基于项目需求和技术特点，我们提供三种数据存储和查询方案：

### 方案一：ClickHouse Redis扩展方案
**适用场景**：需要复杂查询和分析的场景

**架构特点**：
- 利用ClickHouse的Redis扩展功能
- 数据直接从Redis读取到ClickHouse进行查询
- 适合复杂的聚合查询和历史数据分析

**优势**：
- 查询性能优异
- 支持复杂SQL查询
- 数据一致性好

**劣势**：
- 配置复杂
- 实时性相对较低

### 方案二：Redis直接查询方案
**适用场景**：需要极高实时性的场景

**架构特点**：
- 数据直接存储在Redis中
- 查询直接从Redis获取
- 适合实时监控和快速查询

**优势**：
- 实时性最高
- 查询速度极快
- 架构简单

**劣势**：
- 内存占用大
- 不适合复杂查询
- 数据持久化依赖Redis配置

### 方案三：Redis同步写ClickHouse方案（推荐）
**适用场景**：平衡实时性和查询能力的场景

**架构特点**：
- 数据先写入Redis，异步同步到ClickHouse
- Redis提供实时查询，ClickHouse提供历史查询
- 通过物化视图实现多周期数据聚合

**优势**：
- 兼顾实时性和查询能力
- 数据安全性高
- 支持多种查询模式

**劣势**：
- 架构相对复杂
- 需要处理数据同步一致性

## 详细技术方案

### 1. 数据结构设计

#### 日线数据结构
```python
daily_bar_schema = {
    "symbol": "String",        # 股票代码 (如: 000001.SZ)
    "frame": "Date",          # 交易日期
    "open": "Float64",        # 开盘价
    "high": "Float64",        # 最高价
    "low": "Float64",         # 最低价
    "close": "Float64",       # 收盘价
    "vol": "Float64",         # 成交量
    "amount": "Float64",      # 成交额
    "adjust": "Float64",      # 复权因子
    "st": "Bool",             # 是否ST股票
    "limit_up": "Float64",    # 涨停价
    "limit_down": "Float64"   # 跌停价
}
```

#### 分钟线数据结构
```python
minute_bar_schema = {
    "symbol": "String",      # 股票代码 (如: 000001.SZ)
    "frame": "DateTime",     # 时间戳 (精确到分钟)
    "open": "Float64",       # 开盘价
    "high": "Float64",       # 最高价
    "low": "Float64",        # 最低价
    "close": "Float64",      # 收盘价
    "vol": "Float64",        # 成交量
    "amount": "Float64"      # 成交额
}
```

#### Redis数据格式
```python
redis_config = {
    "host": "8.217.201.221",
    "port": 16379,
    "password": None,  # 根据实际情况设置
    "db": 0
}

redis_data_format = {
    "minute_key_pattern": "minute_bar:{symbol}:{date}",
    "daily_key_pattern": "daily_bar:{symbol}:{date}",
    "data_structure": "List",  # 使用List存储当日数据
    "value_format": "JSON",    # JSON格式存储单条数据
    "ttl": 86400 * 7          # 7天过期时间
}
```

### 2. ClickHouse表结构设计

#### 主表：日线数据表
```sql
CREATE TABLE daily_bars (
    symbol String,
    frame Date,
    open Float64,
    high Float64,
    low Float64,
    close Float64,
    vol Float64,
    amount Float64,
    adjust Float64,
    st Bool,
    limit_up Float64,
    limit_down Float64,
    created_at DateTime DEFAULT now()
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(frame)
ORDER BY (symbol, frame)
SETTINGS index_granularity = 8192;
```

#### 主表：分钟线数据表
```sql
CREATE TABLE minute_bars (
    symbol String,
    frame DateTime,
    open Float64,
    high Float64,
    low Float64,
    close Float64,
    vol Float64,
    amount Float64,
    created_at DateTime DEFAULT now()
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(frame)
ORDER BY (symbol, frame)
SETTINGS index_granularity = 8192;
```

#### 物化视图：5分钟线聚合
```sql
CREATE TABLE minute_bars_5min (
    symbol String,
    frame DateTime,
    open Float64,
    high Float64,
    low Float64,
    close Float64,
    vol Float64,
    amount Float64,
    created_at DateTime DEFAULT now()
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(frame)
ORDER BY (symbol, frame)
SETTINGS index_granularity = 8192;

CREATE MATERIALIZED VIEW minute_bars_5min_mv
TO minute_bars_5min
AS SELECT
    symbol,
    toStartOfInterval(frame, INTERVAL 5 MINUTE) as frame,
    argMin(open, frame) as open,
    max(high) as high,
    min(low) as low,
    argMax(close, frame) as close,
    sum(vol) as vol,
    sum(amount) as amount,
    now() as created_at
FROM minute_bars
GROUP BY symbol, frame;
```

#### 物化视图：30分钟线聚合
```sql
CREATE TABLE minute_bars_30min (
    symbol String,
    frame DateTime,
    open Float64,
    high Float64,
    low Float64,
    close Float64,
    vol Float64,
    amount Float64,
    created_at DateTime DEFAULT now()
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(frame)
ORDER BY (symbol, frame)
SETTINGS index_granularity = 8192;

CREATE MATERIALIZED VIEW minute_bars_30min_mv
TO minute_bars_30min
AS SELECT
    symbol,
    toStartOfInterval(frame, INTERVAL 30 MINUTE) as frame,
    argMin(open, frame) as open,
    max(high) as high,
    min(low) as low,
    argMax(close, frame) as close,
    sum(vol) as vol,
    sum(amount) as amount,
    now() as created_at
FROM minute_bars
GROUP BY symbol, frame;
```

### 3. 系统模块设计

#### 3.1 Windows端数据订阅模块 (QMT Subscriber)
```python
class QMTSubscriber:
    """QMT数据订阅器 - Windows端运行"""

    def __init__(self, redis_config, stock_list):
        self.redis_client = redis.StrictRedis(
            host="8.217.201.221",
            port=16379,
            **redis_config
        )
        self.stock_list = stock_list

    def subscribe_minute_data(self):
        """订阅分钟线数据"""
        pass

    def on_minute_data_callback(self, data):
        """分钟线数据回调函数"""
        pass

    def publish_to_redis(self, data):
        """发布数据到远程Redis"""
        pass
```

#### 3.2 Mac端数据消费模块 (Data Consumer)
```python
class DataConsumer:
    """数据消费器 - Mac端运行"""

    def __init__(self, redis_config, clickhouse_config):
        self.redis_client = redis.StrictRedis(
            host="8.217.201.221",
            port=16379,
            **redis_config
        )
        self.clickhouse_client = Client(**clickhouse_config)

    def consume_minute_data(self):
        """消费分钟线数据"""
        pass

    def batch_insert_clickhouse(self, data_batch):
        """批量插入ClickHouse"""
        pass

    def handle_data_validation(self, data):
        """数据验证处理"""
        pass
```

#### 3.3 查询SDK模块 (Query SDK)
```python
class MarketDataSDK:
    """市场数据查询SDK - Mac端运行"""

    def __init__(self, redis_config, clickhouse_config):
        self.redis_client = redis.StrictRedis(
            host="8.217.201.221",
            port=16379,
            **redis_config
        )
        self.clickhouse_client = Client(**clickhouse_config)

    def get_minute_bars(self, symbol, start_time, end_time, period='1min'):
        """获取分钟线数据"""
        pass

    def get_realtime_data(self, symbol):
        """获取实时数据"""
        pass

    def get_daily_bars(self, symbol, start_date, end_date):
        """获取日线数据"""
        pass
```

#### 3.4 Web可视化模块 (Web Interface)
```python
class WebInterface:
    """Web可视化界面 - Mac端运行"""

    def __init__(self, market_data_sdk):
        self.sdk = market_data_sdk
        self.app = Flask(__name__)

    def setup_routes(self):
        """设置路由"""
        pass

    def render_chart_page(self):
        """渲染图表页面"""
        pass

    def api_get_data(self):
        """API接口获取数据"""
        pass
```

### 4. 配置管理

#### Windows端配置文件 (windows_config.yaml)
```yaml
# 远程Redis配置
redis:
  host: 8.217.201.221
  port: 16379
  password: null  # 根据实际情况设置
  db: 0
  decode_responses: true

# QMT配置
qmt:
  data_path: "C:/QMT/data"
  stock_list_file: "stock_list.txt"

# 系统配置
system:
  batch_size: 100
  max_retry_times: 3
  log_level: INFO
  publish_interval: 1  # 发布间隔(秒)
```

#### Mac端配置文件 (mac_config.yaml)
```yaml
# 远程Redis配置
redis:
  host: 8.217.201.221
  port: 16379
  password: null  # 根据实际情况设置
  db: 0
  decode_responses: true

# 本地ClickHouse配置
clickhouse:
  host: localhost
  port: 9000
  database: market_data
  user: default
  password: ""

# Web服务配置
web:
  host: 0.0.0.0
  port: 5000
  debug: true

# 系统配置
system:
  batch_size: 1000
  consumer_threads: 4
  max_retry_times: 3
  log_level: INFO
```

### 5. Web可视化界面设计

#### 5.1 前端页面结构
```html
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>股票数据可视化查询系统</title>
    <script src="https://cdn.jsdelivr.net/npm/echarts@5.4.0/dist/echarts.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/axios/dist/axios.min.js"></script>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/bootstrap.min.css" rel="stylesheet">
</head>
<body>
    <div class="container-fluid">
        <!-- 查询控制面板 -->
        <div class="row mt-3">
            <div class="col-md-12">
                <div class="card">
                    <div class="card-header">
                        <h5>股票数据查询</h5>
                    </div>
                    <div class="card-body">
                        <div class="row">
                            <div class="col-md-2">
                                <label>股票代码:</label>
                                <input type="text" id="symbol" class="form-control" placeholder="000001.SZ">
                            </div>
                            <div class="col-md-2">
                                <label>开始日期:</label>
                                <input type="date" id="start_date" class="form-control">
                            </div>
                            <div class="col-md-2">
                                <label>结束日期:</label>
                                <input type="date" id="end_date" class="form-control">
                            </div>
                            <div class="col-md-2">
                                <label>时间周期:</label>
                                <select id="period" class="form-control">
                                    <option value="1min">1分钟</option>
                                    <option value="5min">5分钟</option>
                                    <option value="30min">30分钟</option>
                                    <option value="daily">日线</option>
                                </select>
                            </div>
                            <div class="col-md-2">
                                <label>&nbsp;</label>
                                <button class="btn btn-primary form-control" onclick="queryData()">查询</button>
                            </div>
                            <div class="col-md-2">
                                <label>&nbsp;</label>
                                <button class="btn btn-success form-control" onclick="getRealTimeData()">实时数据</button>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- 图表展示区域 -->
        <div class="row mt-3">
            <div class="col-md-8">
                <div class="card">
                    <div class="card-header">
                        <h5>K线图</h5>
                    </div>
                    <div class="card-body">
                        <div id="kline_chart" style="height: 500px;"></div>
                    </div>
                </div>
            </div>
            <div class="col-md-4">
                <div class="card">
                    <div class="card-header">
                        <h5>成交量</h5>
                    </div>
                    <div class="card-body">
                        <div id="volume_chart" style="height: 240px;"></div>
                    </div>
                </div>
                <div class="card mt-3">
                    <div class="card-header">
                        <h5>实时信息</h5>
                    </div>
                    <div class="card-body">
                        <div id="realtime_info">
                            <p>请选择股票代码查询实时数据</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</body>
</html>
```

#### 5.2 Flask后端API
```python
from flask import Flask, render_template, request, jsonify
from flask_cors import CORS
import json
from datetime import datetime, timedelta
import pandas as pd

class WebInterface:
    """Web可视化界面"""

    def __init__(self, market_data_sdk):
        self.sdk = market_data_sdk
        self.app = Flask(__name__)
        CORS(self.app)
        self.setup_routes()

    def setup_routes(self):
        """设置路由"""

        @self.app.route('/')
        def index():
            """主页"""
            return render_template('index.html')

        @self.app.route('/api/query_data', methods=['POST'])
        def query_data():
            """查询历史数据API"""
            try:
                data = request.get_json()
                symbol = data.get('symbol')
                start_date = data.get('start_date')
                end_date = data.get('end_date')
                period = data.get('period', '1min')

                # 查询数据
                if period == 'daily':
                    df = self.sdk.get_daily_bars(symbol, start_date, end_date)
                else:
                    start_time = f"{start_date} 09:30:00"
                    end_time = f"{end_date} 15:00:00"
                    df = self.sdk.get_minute_bars(symbol, start_time, end_time, period)

                # 转换为前端需要的格式
                result = self.format_chart_data(df)

                return jsonify({
                    'success': True,
                    'data': result
                })

            except Exception as e:
                return jsonify({
                    'success': False,
                    'error': str(e)
                })

        @self.app.route('/api/realtime_data', methods=['POST'])
        def realtime_data():
            """获取实时数据API"""
            try:
                data = request.get_json()
                symbol = data.get('symbol')

                # 获取实时数据
                realtime_info = self.sdk.get_latest_price(symbol)

                if realtime_info:
                    return jsonify({
                        'success': True,
                        'data': {
                            'symbol': realtime_info['symbol'],
                            'price': realtime_info['close'],
                            'volume': realtime_info['vol'],
                            'amount': realtime_info['amount'],
                            'timestamp': realtime_info['frame']
                        }
                    })
                else:
                    return jsonify({
                        'success': False,
                        'error': '未找到实时数据'
                    })

            except Exception as e:
                return jsonify({
                    'success': False,
                    'error': str(e)
                })

        @self.app.route('/api/market_overview', methods=['GET'])
        def market_overview():
            """市场概览API"""
            try:
                # 热门股票列表
                symbols = ['000001.SZ', '000002.SZ', '600519.SH', '000858.SZ']
                overview = self.sdk.get_market_overview(symbols)

                return jsonify({
                    'success': True,
                    'data': overview
                })

            except Exception as e:
                return jsonify({
                    'success': False,
                    'error': str(e)
                })

    def format_chart_data(self, df):
        """格式化图表数据"""
        if df.empty:
            return {'kline': [], 'volume': [], 'dates': []}

        # K线数据格式: [open, close, low, high]
        kline_data = []
        volume_data = []
        dates = []

        for index, row in df.iterrows():
            dates.append(index.strftime('%Y-%m-%d %H:%M:%S'))
            kline_data.append([
                float(row['open']),
                float(row['close']),
                float(row['low']),
                float(row['high'])
            ])
            volume_data.append(float(row['vol']))

        return {
            'kline': kline_data,
            'volume': volume_data,
            'dates': dates
        }

    def run(self, host='0.0.0.0', port=5000, debug=True):
        """启动Web服务"""
        self.app.run(host=host, port=port, debug=debug)
```

#### 5.3 JavaScript前端逻辑
```javascript
// 初始化图表
let klineChart = echarts.init(document.getElementById('kline_chart'));
let volumeChart = echarts.init(document.getElementById('volume_chart'));

// 查询数据函数
async function queryData() {
    const symbol = document.getElementById('symbol').value;
    const startDate = document.getElementById('start_date').value;
    const endDate = document.getElementById('end_date').value;
    const period = document.getElementById('period').value;

    if (!symbol || !startDate || !endDate) {
        alert('请填写完整的查询条件');
        return;
    }

    try {
        const response = await axios.post('/api/query_data', {
            symbol: symbol,
            start_date: startDate,
            end_date: endDate,
            period: period
        });

        if (response.data.success) {
            updateCharts(response.data.data);
        } else {
            alert('查询失败: ' + response.data.error);
        }
    } catch (error) {
        alert('网络错误: ' + error.message);
    }
}

// 获取实时数据函数
async function getRealTimeData() {
    const symbol = document.getElementById('symbol').value;

    if (!symbol) {
        alert('请输入股票代码');
        return;
    }

    try {
        const response = await axios.post('/api/realtime_data', {
            symbol: symbol
        });

        if (response.data.success) {
            updateRealTimeInfo(response.data.data);
        } else {
            alert('获取实时数据失败: ' + response.data.error);
        }
    } catch (error) {
        alert('网络错误: ' + error.message);
    }
}

// 更新图表
function updateCharts(data) {
    // K线图配置
    const klineOption = {
        title: {
            text: 'K线图'
        },
        tooltip: {
            trigger: 'axis',
            axisPointer: {
                type: 'cross'
            }
        },
        xAxis: {
            type: 'category',
            data: data.dates,
            scale: true,
            boundaryGap: false,
            axisLine: {onZero: false},
            splitLine: {show: false},
            splitNumber: 20,
            min: 'dataMin',
            max: 'dataMax'
        },
        yAxis: {
            scale: true,
            splitArea: {
                show: true
            }
        },
        dataZoom: [
            {
                type: 'inside',
                start: 80,
                end: 100
            },
            {
                show: true,
                type: 'slider',
                top: '90%',
                start: 80,
                end: 100
            }
        ],
        series: [
            {
                name: 'K线',
                type: 'candlestick',
                data: data.kline,
                itemStyle: {
                    color: '#ec0000',
                    color0: '#00da3c',
                    borderColor: '#8A0000',
                    borderColor0: '#008F28'
                }
            }
        ]
    };

    // 成交量图配置
    const volumeOption = {
        title: {
            text: '成交量'
        },
        tooltip: {
            trigger: 'axis'
        },
        xAxis: {
            type: 'category',
            data: data.dates
        },
        yAxis: {
            type: 'value'
        },
        series: [
            {
                name: '成交量',
                type: 'bar',
                data: data.volume,
                itemStyle: {
                    color: '#3398DB'
                }
            }
        ]
    };

    klineChart.setOption(klineOption);
    volumeChart.setOption(volumeOption);
}

// 更新实时信息
function updateRealTimeInfo(data) {
    const infoDiv = document.getElementById('realtime_info');
    infoDiv.innerHTML = `
        <table class="table table-sm">
            <tr><td>股票代码:</td><td>${data.symbol}</td></tr>
            <tr><td>最新价格:</td><td class="text-primary">${data.price}</td></tr>
            <tr><td>成交量:</td><td>${data.volume}</td></tr>
            <tr><td>成交额:</td><td>${data.amount}</td></tr>
            <tr><td>更新时间:</td><td>${data.timestamp}</td></tr>
        </table>
    `;
}

// 页面加载完成后设置默认值
window.onload = function() {
    const today = new Date();
    const lastWeek = new Date(today.getTime() - 7 * 24 * 60 * 60 * 1000);

    document.getElementById('start_date').value = lastWeek.toISOString().split('T')[0];
    document.getElementById('end_date').value = today.toISOString().split('T')[0];
    document.getElementById('symbol').value = '000001.SZ';
};
```

### 6. 性能优化策略

#### 6.1 跨平台数据传输优化
- **数据压缩**：使用JSON压缩减少网络传输量
- **批量传输**：采用批量发送策略，减少网络请求次数
- **连接池**：使用Redis连接池提高连接效率
- **异步处理**：Windows端异步发送，Mac端异步消费

#### 6.2 查询优化
- **索引优化**：合理设计排序键和分区键
- **物化视图**：预计算常用聚合数据
- **缓存策略**：热点数据缓存在Redis中
- **分页查询**：大数据量查询采用分页机制

#### 6.3 Web界面优化
- **前端缓存**：使用浏览器缓存减少重复请求
- **图表优化**：ECharts数据采样和渐进渲染
- **响应式设计**：适配不同屏幕尺寸
- **实时更新**：WebSocket实现数据实时推送

## 实施计划

### 第一阶段：基础环境搭建
1. **远程Redis服务器配置**
   - 在8.217.201.221:16379部署Redis服务
   - 配置网络访问权限和安全设置
   - 测试Windows和Mac的连接性

2. **Mac端ClickHouse环境**
   - 在Mac电脑上安装ClickHouse
   - 创建数据库和表结构
   - 配置本地访问权限

### 第二阶段：Windows端数据采集
1. **QMT数据订阅模块开发**
   - 开发Windows端QMT数据订阅程序
   - 实现分钟线数据实时获取
   - 配置数据发送到远程Redis

2. **数据格式标准化**
   - 统一数据结构定义
   - 实现数据验证和清洗
   - 优化网络传输效率

### 第三阶段：Mac端数据处理
1. **数据消费模块开发**
   - 开发Mac端Redis数据消费程序
   - 实现批量数据处理和存储
   - 创建ClickHouse物化视图

2. **查询SDK开发**
   - 实现多周期数据查询功能
   - 开发Python SDK接口
   - 性能优化和测试

### 第四阶段：Web可视化界面
1. **前端界面开发**
   - 设计响应式Web界面
   - 集成ECharts图表库
   - 实现交互式数据查询

2. **后端API开发**
   - 开发Flask REST API
   - 实现数据查询和格式化
   - 添加实时数据推送功能

### 第五阶段：系统优化和运维
1. **性能优化**
   - 跨平台数据传输优化
   - 查询性能调优
   - 缓存策略实施

2. **监控和运维**
   - 实现系统监控功能
   - 完善日志和异常处理
   - 编写部署和运维文档

## 风险评估与应对

### 技术风险
- **网络连接风险**：跨平台网络连接可能不稳定
  - 应对：实现自动重连机制和连接池管理
  - 备选：配置VPN或专线保障网络稳定性

- **数据丢失风险**：网络中断可能导致数据丢失
  - 应对：Redis持久化配置和ClickHouse备份机制
  - 备选：本地缓存机制，网络恢复后补发数据

- **性能瓶颈风险**：跨网络传输可能影响性能
  - 应对：数据压缩、批量传输和异步处理
  - 备选：增加Redis集群和ClickHouse分片

- **系统稳定性风险**：跨平台部署增加复杂性
  - 应对：完善的异常处理和监控机制
  - 备选：容器化部署和自动故障恢复

### 业务风险
- **数据质量风险**：跨平台传输可能影响数据完整性
  - 应对：数据验证、校验和清洗机制
  - 备选：数据对账和补偿机制

- **实时性要求风险**：网络延迟可能影响实时性
  - 应对：优化网络配置和缓存策略
  - 备选：就近部署和CDN加速

- **平台兼容性风险**：Windows和Mac平台差异
  - 应对：统一数据格式和接口标准
  - 备选：跨平台测试和兼容性验证

## 核心代码实现规范

### 6. Windows端QMT数据订阅实现

#### 6.1 Windows端分钟线数据订阅
```python
import json
import redis
from datetime import datetime
from xtquant import xtdata
import threading
import logging
import time

class QMTMinuteSubscriber:
    """QMT分钟线数据订阅器 - Windows端"""

    def __init__(self, config):
        # 连接远程Redis
        self.redis_client = redis.StrictRedis(
            host="8.217.201.221",
            port=16379,
            password=config.get('redis', {}).get('password'),
            db=config.get('redis', {}).get('db', 0),
            decode_responses=True,
            socket_connect_timeout=5,
            socket_timeout=5,
            retry_on_timeout=True
        )
        self.stock_list = config.get('qmt', {}).get('stock_list', [])
        self.logger = logging.getLogger(__name__)
        self.is_running = False
        self.publish_interval = config.get('system', {}).get('publish_interval', 1)

    def start_subscription(self):
        """启动数据订阅"""
        try:
            # 测试Redis连接
            self.redis_client.ping()
            self.logger.info("Redis连接成功")

            # 订阅分钟线数据
            seq = xtdata.subscribe_quote(
                stock_list=self.stock_list,
                period='1m',
                callback=self.on_minute_data
            )
            self.is_running = True
            self.logger.info(f"开始订阅{len(self.stock_list)}只股票的分钟线数据")

            # 启动数据接收
            xtdata.run()

        except Exception as e:
            self.logger.error(f"订阅数据失败: {e}")

    def on_minute_data(self, data):
        """分钟线数据回调函数"""
        try:
            for symbol, bar_data in data.items():
                minute_bar = {
                    "symbol": symbol,
                    "frame": bar_data['time'],  # 使用frame字段
                    "open": float(bar_data['open']),
                    "high": float(bar_data['high']),
                    "low": float(bar_data['low']),
                    "close": float(bar_data['close']),
                    "vol": float(bar_data['volume']),  # 使用vol字段
                    "amount": float(bar_data['amount'])
                }

                # 发布到Redis
                self.publish_to_redis(minute_bar)

        except Exception as e:
            self.logger.error(f"处理分钟线数据失败: {e}")

    def publish_to_redis(self, minute_bar):
        """发布数据到远程Redis"""
        try:
            # 使用List结构存储当日分钟线数据
            date_str = datetime.now().strftime('%Y-%m-%d')
            key = f"minute_bar:{minute_bar['symbol']}:{date_str}"
            value = json.dumps(minute_bar, ensure_ascii=False, default=str)

            # 推送到当日数据队列
            self.redis_client.lpush(key, value)

            # 设置过期时间（7天）
            self.redis_client.expire(key, 86400 * 7)

            # 同时推送到消费队列
            self.redis_client.lpush("minute_bar_queue", value)

            self.logger.debug(f"发布分钟线数据: {minute_bar['symbol']} - {minute_bar['frame']}")

        except Exception as e:
            self.logger.error(f"发布数据到Redis失败: {e}")
            # 实现重连机制
            self.reconnect_redis()

    def reconnect_redis(self):
        """Redis重连机制"""
        try:
            self.redis_client = redis.StrictRedis(
                host="8.217.201.221",
                port=16379,
                password=None,
                db=0,
                decode_responses=True,
                socket_connect_timeout=5,
                socket_timeout=5,
                retry_on_timeout=True
            )
            self.redis_client.ping()
            self.logger.info("Redis重连成功")
        except Exception as e:
            self.logger.error(f"Redis重连失败: {e}")
```

#### 6.2 Windows端启动脚本
```python
# windows_main.py
import yaml
import logging
from qmt_subscriber import QMTMinuteSubscriber

def setup_logging():
    """配置日志"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('qmt_subscriber.log'),
            logging.StreamHandler()
        ]
    )

def load_config():
    """加载配置文件"""
    with open('windows_config.yaml', 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

def main():
    """主函数"""
    setup_logging()
    logger = logging.getLogger(__name__)

    try:
        # 加载配置
        config = load_config()

        # 创建订阅器
        subscriber = QMTMinuteSubscriber(config)

        # 启动订阅
        logger.info("启动QMT分钟线数据订阅服务...")
        subscriber.start_subscription()

    except KeyboardInterrupt:
        logger.info("用户中断，停止服务")
    except Exception as e:
        logger.error(f"服务异常: {e}")

if __name__ == "__main__":
    main()
```

### 7. Mac端数据消费与存储实现

#### 7.1 Mac端数据消费器
```python
import json
import time
import redis
from clickhouse_driver import Client
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime
import logging

class MacDataConsumer:
    """Mac端数据消费器"""

    def __init__(self, config):
        # 连接远程Redis
        self.redis_client = redis.StrictRedis(
            host="8.217.201.221",
            port=16379,
            password=config.get('redis', {}).get('password'),
            db=config.get('redis', {}).get('db', 0),
            decode_responses=True,
            socket_connect_timeout=5,
            socket_timeout=5,
            retry_on_timeout=True
        )

        # 连接本地ClickHouse
        self.clickhouse_client = Client(
            host=config.get('clickhouse', {}).get('host', 'localhost'),
            port=config.get('clickhouse', {}).get('port', 9000),
            database=config.get('clickhouse', {}).get('database', 'market_data'),
            user=config.get('clickhouse', {}).get('user', 'default'),
            password=config.get('clickhouse', {}).get('password', '')
        )

        self.batch_size = config.get('system', {}).get('batch_size', 1000)
        self.logger = logging.getLogger(__name__)
        self.is_running = False

    def start_consuming(self, num_workers=4):
        """启动消费进程"""
        self.is_running = True
        self.logger.info("启动Mac端数据消费服务...")

        # 测试连接
        try:
            self.redis_client.ping()
            self.clickhouse_client.execute("SELECT 1")
            self.logger.info("Redis和ClickHouse连接成功")
        except Exception as e:
            self.logger.error(f"连接测试失败: {e}")
            return

        with ThreadPoolExecutor(max_workers=num_workers) as executor:
            futures = []
            for i in range(num_workers):
                future = executor.submit(self.consume_worker, f"worker-{i}")
                futures.append(future)

            # 等待所有工作线程完成
            for future in futures:
                future.result()

    def consume_worker(self, worker_name):
        """消费工作线程"""
        self.logger.info(f"启动消费工作线程: {worker_name}")

        batch_data = []
        last_insert_time = time.time()

        while self.is_running:
            try:
                # 从队列中获取数据
                result = self.redis_client.brpop("minute_bar_queue", timeout=1)

                if result is None:
                    # 队列为空，检查是否需要批量插入
                    if batch_data and (time.time() - last_insert_time) > 5:
                        self.batch_insert_clickhouse(batch_data)
                        batch_data = []
                        last_insert_time = time.time()
                    continue

                _, json_data = result
                minute_bar = json.loads(json_data)
                batch_data.append(minute_bar)

                # 达到批量大小或超时，执行批量插入
                if len(batch_data) >= self.batch_size or (time.time() - last_insert_time) > 10:
                    self.batch_insert_clickhouse(batch_data)
                    batch_data = []
                    last_insert_time = time.time()

            except Exception as e:
                self.logger.error(f"消费数据异常 [{worker_name}]: {e}")
                time.sleep(1)

        # 处理剩余数据
        if batch_data:
            self.batch_insert_clickhouse(batch_data)

    def batch_insert_clickhouse(self, batch_data):
        """批量插入ClickHouse"""
        try:
            if not batch_data:
                return

            query = """
            INSERT INTO minute_bars
            (symbol, frame, open, high, low, close, vol, amount, created_at)
            VALUES
            """

            values = []
            for bar in batch_data:
                values.append((
                    bar['symbol'],
                    datetime.fromisoformat(bar['frame']) if isinstance(bar['frame'], str) else bar['frame'],
                    bar['open'],
                    bar['high'],
                    bar['low'],
                    bar['close'],
                    bar['vol'],
                    bar['amount'],
                    datetime.now()
                ))

            self.clickhouse_client.execute(query, values)
            self.logger.info(f"成功插入{len(batch_data)}条分钟线数据")

        except Exception as e:
            self.logger.error(f"批量插入ClickHouse失败: {e}")

    def stop_consuming(self):
        """停止消费"""
        self.is_running = False
        self.logger.info("停止数据消费")
```

#### 7.2 Mac端查询SDK
```python
import pandas as pd
from datetime import datetime, timedelta
from typing import Optional, List, Dict, Any
import json

class MacMarketDataSDK:
    """Mac端市场数据查询SDK"""

    def __init__(self, config):
        # 连接远程Redis
        self.redis_client = redis.StrictRedis(
            host="8.217.201.221",
            port=16379,
            password=config.get('redis', {}).get('password'),
            db=config.get('redis', {}).get('db', 0),
            decode_responses=True
        )

        # 连接本地ClickHouse
        self.clickhouse_client = Client(
            host=config.get('clickhouse', {}).get('host', 'localhost'),
            port=config.get('clickhouse', {}).get('port', 9000),
            database=config.get('clickhouse', {}).get('database', 'market_data'),
            user=config.get('clickhouse', {}).get('user', 'default'),
            password=config.get('clickhouse', {}).get('password', '')
        )

        self.logger = logging.getLogger(__name__)

    def get_minute_bars(self, symbol: str, start_time: str, end_time: str,
                       period: str = '1min') -> pd.DataFrame:
        """
        获取分钟线数据

        Args:
            symbol: 股票代码
            start_time: 开始时间 (YYYY-MM-DD HH:MM:SS)
            end_time: 结束时间 (YYYY-MM-DD HH:MM:SS)
            period: 时间周期 ('1min', '5min', '30min')

        Returns:
            pandas.DataFrame: 分钟线数据
        """
        try:
            # 根据周期选择表名
            table_map = {
                '1min': 'minute_bars',
                '5min': 'minute_bars_5min',
                '30min': 'minute_bars_30min'
            }

            table_name = table_map.get(period, 'minute_bars')

            query = f"""
            SELECT
                symbol,
                frame,
                open,
                high,
                low,
                close,
                vol,
                amount
            FROM {table_name}
            WHERE symbol = %(symbol)s
              AND frame >= %(start_time)s
              AND frame <= %(end_time)s
            ORDER BY frame
            """

            result = self.clickhouse_client.execute(
                query,
                {
                    'symbol': symbol,
                    'start_time': start_time,
                    'end_time': end_time
                }
            )

            # 转换为DataFrame
            columns = ['symbol', 'frame', 'open', 'high', 'low', 'close', 'vol', 'amount']
            df = pd.DataFrame(result, columns=columns)
            if not df.empty:
                df.set_index('frame', inplace=True)

            return df

        except Exception as e:
            self.logger.error(f"查询分钟线数据失败: {e}")
            return pd.DataFrame()

    def get_daily_bars(self, symbol: str, start_date: str, end_date: str) -> pd.DataFrame:
        """
        获取日线数据

        Args:
            symbol: 股票代码
            start_date: 开始日期 (YYYY-MM-DD)
            end_date: 结束日期 (YYYY-MM-DD)

        Returns:
            pandas.DataFrame: 日线数据
        """
        try:
            query = """
            SELECT
                symbol,
                frame,
                open,
                high,
                low,
                close,
                vol,
                amount,
                adjust,
                st,
                limit_up,
                limit_down
            FROM daily_bars
            WHERE symbol = %(symbol)s
              AND frame >= %(start_date)s
              AND frame <= %(end_date)s
            ORDER BY frame
            """

            result = self.clickhouse_client.execute(
                query,
                {
                    'symbol': symbol,
                    'start_date': start_date,
                    'end_date': end_date
                }
            )

            # 转换为DataFrame
            columns = ['symbol', 'frame', 'open', 'high', 'low', 'close', 'vol', 'amount',
                      'adjust', 'st', 'limit_up', 'limit_down']
            df = pd.DataFrame(result, columns=columns)
            if not df.empty:
                df.set_index('frame', inplace=True)

            return df

        except Exception as e:
            self.logger.error(f"查询日线数据失败: {e}")
            return pd.DataFrame()

    def get_realtime_data(self, symbol: str, date: Optional[str] = None) -> List[Dict[str, Any]]:
        """
        获取实时数据（从Redis）

        Args:
            symbol: 股票代码
            date: 日期 (YYYY-MM-DD)，默认为今天

        Returns:
            List[Dict]: 实时分钟线数据列表
        """
        try:
            if date is None:
                date = datetime.now().strftime('%Y-%m-%d')

            key = f"minute_bar:{symbol}:{date}"

            # 从Redis获取当日数据
            data_list = self.redis_client.lrange(key, 0, -1)

            result = []
            for data in data_list:
                minute_bar = json.loads(data)
                result.append(minute_bar)

            # 按时间排序
            result.sort(key=lambda x: x['frame'])

            return result

        except Exception as e:
            self.logger.error(f"获取实时数据失败: {e}")
            return []

    def get_latest_price(self, symbol: str) -> Optional[Dict[str, Any]]:
        """
        获取最新价格

        Args:
            symbol: 股票代码

        Returns:
            Dict: 最新价格信息
        """
        try:
            date = datetime.now().strftime('%Y-%m-%d')
            key = f"minute_bar:{symbol}:{date}"

            # 获取最新一条数据
            latest_data = self.redis_client.lindex(key, 0)

            if latest_data:
                return json.loads(latest_data)
            else:
                return None

        except Exception as e:
            self.logger.error(f"获取最新价格失败: {e}")
            return None
```

### 7. 数据消费与存储

#### 7.1 Redis消费者
```python
import json
import time
from clickhouse_driver import Client
from concurrent.futures import ThreadPoolExecutor

class MinuteBarConsumer:
    """分钟线数据消费者"""

    def __init__(self, redis_config, clickhouse_config, batch_size=100):
        self.redis_client = redis.StrictRedis(**redis_config)
        self.clickhouse_client = Client(**clickhouse_config)
        self.batch_size = batch_size
        self.logger = logging.getLogger(__name__)
        self.is_running = False

    def start_consuming(self, num_workers=4):
        """启动消费进程"""
        self.is_running = True

        with ThreadPoolExecutor(max_workers=num_workers) as executor:
            futures = []
            for i in range(num_workers):
                future = executor.submit(self.consume_worker, f"worker-{i}")
                futures.append(future)

            # 等待所有工作线程完成
            for future in futures:
                future.result()

    def consume_worker(self, worker_name):
        """消费工作线程"""
        self.logger.info(f"启动消费工作线程: {worker_name}")

        batch_data = []
        last_insert_time = time.time()

        while self.is_running:
            try:
                # 从队列中获取数据
                result = self.redis_client.brpop("minute_bar_queue", timeout=1)

                if result is None:
                    # 队列为空，检查是否需要批量插入
                    if batch_data and (time.time() - last_insert_time) > 5:
                        self.batch_insert_clickhouse(batch_data)
                        batch_data = []
                        last_insert_time = time.time()
                    continue

                _, json_data = result
                minute_bar = json.loads(json_data)
                batch_data.append(minute_bar)

                # 达到批量大小或超时，执行批量插入
                if len(batch_data) >= self.batch_size or (time.time() - last_insert_time) > 10:
                    self.batch_insert_clickhouse(batch_data)
                    batch_data = []
                    last_insert_time = time.time()

            except Exception as e:
                self.logger.error(f"消费数据异常 [{worker_name}]: {e}")
                time.sleep(1)

        # 处理剩余数据
        if batch_data:
            self.batch_insert_clickhouse(batch_data)

    def batch_insert_clickhouse(self, batch_data):
        """批量插入ClickHouse"""
        try:
            if not batch_data:
                return

            query = """
            INSERT INTO minute_bars
            (symbol, timestamp, open, high, low, close, volume, amount, trade_date, created_at)
            VALUES
            """

            values = []
            for bar in batch_data:
                values.append((
                    bar['symbol'],
                    datetime.strptime(bar['timestamp'], '%Y-%m-%d %H:%M:%S'),
                    bar['open'],
                    bar['high'],
                    bar['low'],
                    bar['close'],
                    bar['volume'],
                    bar['amount'],
                    datetime.strptime(bar['trade_date'], '%Y-%m-%d').date(),
                    datetime.fromisoformat(bar['created_at'])
                ))

            self.clickhouse_client.execute(query, values)
            self.logger.info(f"成功插入{len(batch_data)}条分钟线数据")

        except Exception as e:
            self.logger.error(f"批量插入ClickHouse失败: {e}")

    def stop_consuming(self):
        """停止消费"""
        self.is_running = False
        self.logger.info("停止数据消费")
```

### 8. 查询SDK实现

#### 8.1 多周期数据查询
```python
import pandas as pd
from datetime import datetime, timedelta
from typing import Optional, List, Dict, Any

class MarketDataSDK:
    """市场数据查询SDK"""

    def __init__(self, redis_config, clickhouse_config):
        self.redis_client = redis.StrictRedis(**redis_config)
        self.clickhouse_client = Client(**clickhouse_config)
        self.logger = logging.getLogger(__name__)

    def get_minute_bars(self, symbol: str, start_time: str, end_time: str,
                       period: str = '1min') -> pd.DataFrame:
        """
        获取分钟线数据

        Args:
            symbol: 股票代码
            start_time: 开始时间 (YYYY-MM-DD HH:MM:SS)
            end_time: 结束时间 (YYYY-MM-DD HH:MM:SS)
            period: 时间周期 ('1min', '5min', '30min', 'daily')

        Returns:
            pandas.DataFrame: 分钟线数据
        """
        try:
            # 根据周期选择表名
            table_map = {
                '1min': 'minute_bars',
                '5min': 'minute_bars_5min',
                '30min': 'minute_bars_30min',
                'daily': 'minute_bars_daily'
            }

            table_name = table_map.get(period, 'minute_bars')

            query = f"""
            SELECT
                symbol,
                timestamp,
                open,
                high,
                low,
                close,
                volume,
                amount
            FROM {table_name}
            WHERE symbol = %(symbol)s
              AND timestamp >= %(start_time)s
              AND timestamp <= %(end_time)s
            ORDER BY timestamp
            """

            result = self.clickhouse_client.execute(
                query,
                {
                    'symbol': symbol,
                    'start_time': start_time,
                    'end_time': end_time
                }
            )

            # 转换为DataFrame
            columns = ['symbol', 'timestamp', 'open', 'high', 'low', 'close', 'volume', 'amount']
            df = pd.DataFrame(result, columns=columns)
            df.set_index('timestamp', inplace=True)

            return df

        except Exception as e:
            self.logger.error(f"查询分钟线数据失败: {e}")
            return pd.DataFrame()

    def get_realtime_data(self, symbol: str, date: Optional[str] = None) -> List[Dict[str, Any]]:
        """
        获取实时数据（从Redis）

        Args:
            symbol: 股票代码
            date: 日期 (YYYY-MM-DD)，默认为今天

        Returns:
            List[Dict]: 实时分钟线数据列表
        """
        try:
            if date is None:
                date = datetime.now().strftime('%Y-%m-%d')

            key = f"minute_bar:{symbol}:{date}"

            # 从Redis获取当日数据
            data_list = self.redis_client.lrange(key, 0, -1)

            result = []
            for data in data_list:
                minute_bar = json.loads(data)
                result.append(minute_bar)

            # 按时间排序
            result.sort(key=lambda x: x['timestamp'])

            return result

        except Exception as e:
            self.logger.error(f"获取实时数据失败: {e}")
            return []

    def get_latest_price(self, symbol: str) -> Optional[Dict[str, Any]]:
        """
        获取最新价格

        Args:
            symbol: 股票代码

        Returns:
            Dict: 最新价格信息
        """
        try:
            date = datetime.now().strftime('%Y-%m-%d')
            key = f"minute_bar:{symbol}:{date}"

            # 获取最新一条数据
            latest_data = self.redis_client.lindex(key, 0)

            if latest_data:
                return json.loads(latest_data)
            else:
                return None

        except Exception as e:
            self.logger.error(f"获取最新价格失败: {e}")
            return None

    def get_market_overview(self, symbols: List[str]) -> Dict[str, Dict[str, Any]]:
        """
        获取市场概览

        Args:
            symbols: 股票代码列表

        Returns:
            Dict: 市场概览数据
        """
        try:
            result = {}

            for symbol in symbols:
                latest_price = self.get_latest_price(symbol)
                if latest_price:
                    result[symbol] = {
                        'latest_price': latest_price['close'],
                        'timestamp': latest_price['timestamp'],
                        'volume': latest_price['volume'],
                        'amount': latest_price['amount']
                    }

            return result

        except Exception as e:
            self.logger.error(f"获取市场概览失败: {e}")
            return {}
```

### 9. 系统监控与运维

#### 9.1 性能监控
```python
import psutil
import time
from datetime import datetime

class SystemMonitor:
    """系统监控器"""

    def __init__(self, redis_config, clickhouse_config):
        self.redis_client = redis.StrictRedis(**redis_config)
        self.clickhouse_client = Client(**clickhouse_config)
        self.logger = logging.getLogger(__name__)

    def monitor_system_resources(self):
        """监控系统资源"""
        try:
            # CPU使用率
            cpu_percent = psutil.cpu_percent(interval=1)

            # 内存使用率
            memory = psutil.virtual_memory()
            memory_percent = memory.percent

            # 磁盘使用率
            disk = psutil.disk_usage('/')
            disk_percent = disk.percent

            # Redis连接数
            redis_info = self.redis_client.info()
            redis_connections = redis_info.get('connected_clients', 0)

            # ClickHouse查询统计
            ch_query = "SELECT count() FROM system.processes WHERE query != ''"
            ch_active_queries = self.clickhouse_client.execute(ch_query)[0][0]

            monitor_data = {
                'timestamp': datetime.now().isoformat(),
                'cpu_percent': cpu_percent,
                'memory_percent': memory_percent,
                'disk_percent': disk_percent,
                'redis_connections': redis_connections,
                'clickhouse_active_queries': ch_active_queries
            }

            # 记录监控数据
            self.logger.info(f"系统监控: {monitor_data}")

            # 检查告警条件
            self.check_alerts(monitor_data)

            return monitor_data

        except Exception as e:
            self.logger.error(f"系统监控失败: {e}")
            return {}

    def check_alerts(self, monitor_data):
        """检查告警条件"""
        alerts = []

        if monitor_data['cpu_percent'] > 80:
            alerts.append(f"CPU使用率过高: {monitor_data['cpu_percent']}%")

        if monitor_data['memory_percent'] > 85:
            alerts.append(f"内存使用率过高: {monitor_data['memory_percent']}%")

        if monitor_data['disk_percent'] > 90:
            alerts.append(f"磁盘使用率过高: {monitor_data['disk_percent']}%")

        if monitor_data['redis_connections'] > 1000:
            alerts.append(f"Redis连接数过多: {monitor_data['redis_connections']}")

        if alerts:
            for alert in alerts:
                self.logger.warning(f"系统告警: {alert}")

    def monitor_data_quality(self):
        """监控数据质量"""
        try:
            # 检查今日数据量
            today = datetime.now().strftime('%Y-%m-%d')
            query = """
            SELECT
                symbol,
                count() as record_count,
                min(timestamp) as first_record,
                max(timestamp) as last_record
            FROM minute_bars
            WHERE trade_date = %(today)s
            GROUP BY symbol
            ORDER BY record_count DESC
            """

            result = self.clickhouse_client.execute(query, {'today': today})

            data_quality_report = []
            for row in result:
                symbol, count, first_time, last_time = row
                data_quality_report.append({
                    'symbol': symbol,
                    'record_count': count,
                    'first_record': first_time,
                    'last_record': last_time
                })

            self.logger.info(f"今日数据质量报告: 共{len(data_quality_report)}只股票")

            return data_quality_report

        except Exception as e:
            self.logger.error(f"数据质量监控失败: {e}")
            return []
```

## 部署与运维指南

### 10. 环境部署

#### 10.1 Docker部署方案
```yaml
# docker-compose.yml
version: '3.8'

services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    command: redis-server --requirepass quantide666
    volumes:
      - redis_data:/data
    restart: unless-stopped

  clickhouse:
    image: clickhouse/clickhouse-server:latest
    ports:
      - "9000:9000"
      - "8123:8123"
    volumes:
      - clickhouse_data:/var/lib/clickhouse
      - ./clickhouse-config.xml:/etc/clickhouse-server/config.xml
    restart: unless-stopped

  minute-subscriber:
    build: .
    command: python -m src.qmt_subscriber
    depends_on:
      - redis
      - clickhouse
    volumes:
      - ./config.yaml:/app/config.yaml
    restart: unless-stopped

  minute-consumer:
    build: .
    command: python -m src.minute_consumer
    depends_on:
      - redis
      - clickhouse
    volumes:
      - ./config.yaml:/app/config.yaml
    restart: unless-stopped

volumes:
  redis_data:
  clickhouse_data:
```

#### 10.2 系统启动脚本
```bash
#!/bin/bash
# start_system.sh

echo "启动分钟线数据实时订阅系统..."

# 检查Docker环境
if ! command -v docker-compose &> /dev/null; then
    echo "错误: 请先安装docker-compose"
    exit 1
fi

# 启动基础服务
echo "启动Redis和ClickHouse..."
docker-compose up -d redis clickhouse

# 等待服务启动
sleep 10

# 初始化ClickHouse表结构
echo "初始化ClickHouse表结构..."
python scripts/init_clickhouse.py

# 启动数据订阅服务
echo "启动数据订阅服务..."
docker-compose up -d minute-subscriber

# 启动数据消费服务
echo "启动数据消费服务..."
docker-compose up -d minute-consumer

echo "系统启动完成！"
echo "Redis: localhost:6379"
echo "ClickHouse: localhost:9000"
echo "查看日志: docker-compose logs -f"
```

### 11. 运维监控

#### 11.1 日志管理
```python
# logging_config.py
import logging
import logging.handlers
import os

def setup_logging(log_level='INFO', log_file='minute_bar_system.log'):
    """配置日志系统"""

    # 创建日志目录
    log_dir = 'logs'
    if not os.path.exists(log_dir):
        os.makedirs(log_dir)

    log_file_path = os.path.join(log_dir, log_file)

    # 配置日志格式
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    # 文件处理器（支持日志轮转）
    file_handler = logging.handlers.RotatingFileHandler(
        log_file_path,
        maxBytes=10*1024*1024,  # 10MB
        backupCount=5
    )
    file_handler.setFormatter(formatter)

    # 控制台处理器
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)

    # 配置根日志器
    root_logger = logging.getLogger()
    root_logger.setLevel(getattr(logging, log_level.upper()))
    root_logger.addHandler(file_handler)
    root_logger.addHandler(console_handler)

    return root_logger
```

#### 11.2 健康检查
```python
# health_check.py
import requests
import redis
from clickhouse_driver import Client

class HealthChecker:
    """系统健康检查"""

    def __init__(self, config):
        self.config = config

    def check_redis_health(self):
        """检查Redis健康状态"""
        try:
            r = redis.StrictRedis(**self.config['redis'])
            r.ping()
            return True, "Redis连接正常"
        except Exception as e:
            return False, f"Redis连接失败: {e}"

    def check_clickhouse_health(self):
        """检查ClickHouse健康状态"""
        try:
            client = Client(**self.config['clickhouse'])
            result = client.execute("SELECT 1")
            return True, "ClickHouse连接正常"
        except Exception as e:
            return False, f"ClickHouse连接失败: {e}"

    def check_data_freshness(self):
        """检查数据新鲜度"""
        try:
            client = Client(**self.config['clickhouse'])
            query = """
            SELECT max(created_at) as latest_time
            FROM minute_bars
            WHERE trade_date = today()
            """
            result = client.execute(query)

            if result and result[0][0]:
                latest_time = result[0][0]
                time_diff = datetime.now() - latest_time

                if time_diff.total_seconds() < 300:  # 5分钟内
                    return True, f"数据新鲜，最新时间: {latest_time}"
                else:
                    return False, f"数据过期，最新时间: {latest_time}"
            else:
                return False, "今日无数据"

        except Exception as e:
            return False, f"数据新鲜度检查失败: {e}"

    def run_health_check(self):
        """运行完整健康检查"""
        checks = [
            ("Redis", self.check_redis_health),
            ("ClickHouse", self.check_clickhouse_health),
            ("数据新鲜度", self.check_data_freshness)
        ]

        results = {}
        all_healthy = True

        for name, check_func in checks:
            is_healthy, message = check_func()
            results[name] = {
                'healthy': is_healthy,
                'message': message
            }

            if not is_healthy:
                all_healthy = False

        return all_healthy, results
```

## 总结

本方案采用跨平台的Redis同步写ClickHouse架构，通过Windows端QMT数据采集、远程Redis数据传输、Mac端ClickHouse存储查询的完整链路，既保证了数据的实时性，又提供了强大的查询和分析能力。同时集成Web可视化界面，为用户提供简洁易用的数据查询和图表展示功能。

### 核心优势

#### 1. 跨平台兼容性
- **Windows端专业数据源**：充分利用QMT在Windows平台的优势
- **Mac端高效查询**：发挥ClickHouse在Mac环境下的性能优势
- **统一数据格式**：确保跨平台数据传输的一致性和完整性

#### 2. 高性能数据处理
- **实时数据传输**：通过远程Redis实现毫秒级数据传输
- **批量处理优化**：Mac端批量消费和存储，提高写入效率
- **物化视图聚合**：自动生成多周期数据，优化查询性能

#### 3. 用户友好界面
- **Web可视化查询**：提供直观的K线图和成交量图表
- **实时数据展示**：支持实时价格和市场概览查询
- **响应式设计**：适配不同设备和屏幕尺寸

#### 4. 系统可靠性
- **双重存储保障**：Redis缓存 + ClickHouse持久化
- **自动重连机制**：网络中断自动恢复连接
- **完善异常处理**：全链路异常监控和处理

#### 5. 易于扩展维护
- **模块化设计**：各组件独立部署，便于维护升级
- **配置化管理**：通过配置文件灵活调整系统参数
- **完善日志系统**：支持问题排查和性能监控

### 技术特色

#### 数据链路设计
```
Windows(QMT) → 远程Redis(8.217.201.221:16379) → Mac(ClickHouse) → Web界面
     ↓                    ↓                           ↓              ↓
  实时数据采集         跨平台数据缓冲              本地高效存储    可视化展示
```

#### 数据结构优化
- **日线数据**：包含完整的OHLCV、复权因子、ST状态、涨跌停价格
- **分钟线数据**：精简的OHLCV结构，优化传输和存储效率
- **统一字段命名**：使用frame字段统一时间维度

#### 性能优化策略
- **网络传输优化**：JSON压缩、批量发送、连接池管理
- **存储优化**：ClickHouse分区、排序键、物化视图
- **查询优化**：索引设计、缓存策略、分页查询

### 应用场景

#### 1. 量化策略研发
- 实时获取市场数据进行策略验证
- 历史数据回测和策略优化
- 多周期数据分析和因子挖掘

#### 2. 实时监控系统
- 盘中实时价格监控
- 异常波动预警
- 市场概览和热点追踪

#### 3. 数据分析平台
- 交互式数据查询和可视化
- 自定义图表和指标计算
- 数据导出和报表生成

### 部署建议

#### 生产环境优化
1. **网络优化**：配置专线或VPN保障网络稳定性
2. **硬件配置**：Redis服务器配置高速SSD，ClickHouse配置大内存
3. **监控告警**：部署Prometheus + Grafana监控系统
4. **备份策略**：定期备份ClickHouse数据和Redis持久化文件

#### 扩展方案
1. **水平扩展**：Redis集群 + ClickHouse分片
2. **高可用**：Redis主从 + ClickHouse副本
3. **负载均衡**：Web服务多实例部署
4. **CDN加速**：静态资源CDN分发

该系统可以作为量化交易平台的核心数据基础设施，为策略研发、回测分析、实时监控等业务场景提供强有力的数据支撑。通过跨平台架构设计，充分发挥了各平台的技术优势，实现了高性能、高可靠、易使用的数据处理解决方案。
